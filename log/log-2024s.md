### 用于记录日常

##### 20240313

- 根据 xilinx embeddedsw 仓库修改 axi-dma 驱动，目前的缺陷
  - 目前的驱动对于 buffer descriptor 的状态管理不够完善，alloc 和 free 与 toHW 和 fromHW 紧耦合
  - buffer descriptor ring 的状态管理没有
  - 缺少中断合并的功能：需要设置 threshold 或者 delay timer counter
  - 所有用于传输的地址都必须是物理地址，在用户态使用还需要建立专门的缓冲区，或者在用户态维护地址映射关系
  - 缓存一致性、地址对齐
  - 恢复：软件记录当前的 BD，下一次可直接从当前 BD 开始
  - 同步互斥需要软件方面提供
- 完善目前的驱动
  - 由于一些设置的原因，导致出现了错误，根据手册的提示是因为没有设置描述符对应的缓冲区长度，但已经设置了

##### 20240312

- 组会
- 配置 ldh 可以运行的 FPGA 环境（uintr-rocket-chip）
  - 没有初始化 rocket-chip 子仓库，导致报错
- ila 抓信号，测 DMA 性能
  - 无法抓到 mm2s tlast 信号
  - 抓 arvalid 信号与 mm2s_introut 信号，比较第一次 arvalid 信号与 mm2s_introut 这两个信号测量中间的时间间隔
  - 没有把 mm2s_introut 线标记为 debug，导致不能看到信号，并且也产生不了中断
  - 标记了 debug 之后，还是无法产生中断
  - 同时抓 arvalid 与 mm2s_introut 信号，导致 DMA 的行为异常
  - 综合后，从网表中标记 debug
  - 由于采样窗口过短，导致不能看到 mm2s_introut 拉高的波形
  - 延长采样窗口后看到 tlast 信号
  - 最终的测试结果如下：

| 字节数 | 时钟周期 | 微秒 | arvalid - tlast（采样窗口） | 吞吐量（KB/s） |
| ----- | ------- | --- | ------------------------- | ------------- |
| 1000  | 189056  | 18905 | 910                     | 52.89         |
| 2000  | 188934  | 18893 | 1650                    | 105.86        |
| 4000  | 785     | 78    | > 4096                  | 51282.05      |
| 4096  | 800     | 80    | > 4096                  | 51200.00      |
| 8000  | 1100    | 110   | > 4096                  | 72727.27      |
| 8192  | 1130    | 113   | > 4096                  | 72495.58      |
| 10000 | 1240    | 124   | > 4096                  | 80645.16      |
| 20000 | 750     | 75    | 2300                    | 266666.67     |
| 25000 | 1000    | 100   | > 4096                  | 250000.00     |

- 根据 xilinx embeddedsw 仓库修改 axi-dma 驱动

##### 20240311

- 阅读 AXI-DMA 手册
  - MM2S 通道的吞吐量测试从 Memory Map 端的第一个 arvalid 信号到 stream 端的 tlast 信号
  - S2MM 通道的吞吐量测试从 stream 端的第一个 tvalid 信号到 Memory Map 端的最后一个 wlast 信号
- 讨论设计方案
  - 修改设计方案中的地址空间分配，将外部设备的地址划分到每个进程
- 测试 AXI-DMA 的性能
  - 使用 ila 抓 MM2S 通道的 arvalid 和 tlast 信号，使用 baremental 仓库里的测例
  - 只能抓到 MM 端的 arvalid  的信号和 stream control_tlast 信号（46 - 54 个采样窗口），抓不到 Stream 端的 tlast 信号
  - 抓 sg_arvalid 信号，但是不能抓到 mm2s_arvalid 和其他信号
  - 总是抓不到文档中提到的 tlast 信号
  - 且使用同步的 DMA 驱动测试代码，在启动时遇到了其他的问题

##### 20240310

- 去野生动物园
- 阅读 AXI-DMA 手册

##### 20240309
- 先把连接到 ATSINTC 的中断线断开，测试 plic 能不能正常工作
  - 运行裸机测试的时候，卡在了 dma 发送的通道，从对应的寄存器中读不到中断，一直没有产生中断
  - ldh 也遇到了同样收不到中断的问题，可能的原因是使用同一个 opensbi，没有让 s 态代理外部中断，查看 opensbi 代码，发现使能了 s 态代理中断
  - 测试了 arceos 里的 redis server，能够正常工作，但没有用到 PLIC 相关的代码
  - 把 ATSINTC 这个设备完全移除，还是不能收到中断信号
  - 时钟中断可以产生，但有些奇怪
- 把一个 gpio 连接到 rocket 和 ps 侧，ps 侧通过操作 gpio 来模拟产生中断
- 使用 ila 抓信号
  - 抓 gpio，ps 侧的操作可以看到波形变化
  - 抓 ext_intrs 信号线
  - 抓 plic 中的 gateways_gateway_5_io_interrupt 信号，中断信号已经发到 plic 的 gateway 了
  - 抓 core_io_interrupts_seip，查看外部中断信号是否发给了 CPU，信号被拉高了
  - 在 1 个核的情况下，突然发现能够触发中断，然后换成 4 个核之后又不能触发中断
  - 因为测试代码初始化的原因，导致了不能触发中断，修改后能够触发中断
- 在测试代码中注册好中断处理协程后，软件轮循读取中断处理协程，ps 侧操作 gpio 模拟产生中断，成功唤醒了阻塞的协程
  - 注册中断处理协程后，用网卡发送一个数据包，马上唤醒了阻塞在 dma 发送通道的协程

##### 20240308

- 测试硬件逻辑，LUT 占用率仍然是 80%
  - 使用 MMIO 寄存器来模拟产生外部中断，导致中断控制器里输入端的中断线没有连接到设备的中断线上，注释掉对应的 MMIO 寄存器之后，可以看到连接上了
  - `assign queue_io_intrs_0 = auto_int_in_0; // @[Nodes.scala 1210:84 LazyModule.scala 309:16]`
  - 上板子测试，ping 网卡，但是没有唤醒对应的协程，不能从中获取到中断处理协程，想起来是因为网卡没有初始化
  - 网卡初始化之后，还是没有唤醒协程，从发数据包来看，没有收到中断信号，从对应的寄存器中读不到相关信息
  - 一种可能的原因是外部中断线同时连到了 plic 和 atsintc 上，导致在生成 verilog 时出现问题，原本的使用 plic 的测例也不能正常工作

##### 20240307

- 花了半天的时间做了一个微信小程序来记录个人以及好友的读书详情
- 测试硬件逻辑
  - 在 verilator 中测试正常
  - 上板子测试，LUT: 53% -> 82%，优先级队列的基本功能仍然正常，但是外设的阻塞队列出队顺序不对， 按照这种情况，估计是由于资源占用过多导致的，并且外设里阻塞的协程是较高级的抽象，因此这个顺序没有影响
  - 把阻塞队列从 256 换成 128，LUT：82% -> 63%，原来不是出了问题，在 verilator 里的仿真结果也是顺序反过来了
  - 因为把队列的 position 固定死了为 0，所以它变成了栈，因此顺序反过来了，将队列从 DataArray 改成 PriorityQueue 后，顺序是正确的了，但 LUT 又回到了 81%，把 DataArray 的 length 接口暴露出来，用于g指定作为队列时的入队位置
- 尝试改 arceos 的驱动代码

##### 20240306

- 调试
  - 打开生成的 verilog 文件，看不到中断处理模块的入队和出队数据信号线
  - 主要的问题在与和优先级队列的连接方式，导致没有生成出队入队信号线
  - 将出队的接口连接到 MMIO 寄存器上，生成了对应的信号线，但是这个接口不需要连接到 MMIO 寄存器上，在写优先级队列时也存在同样的问题，应该是被 firrtl 优化了
- 写带有中断处理的优先级队列
  - 能够正常唤醒中断处理协程了
  - 但是不同的阻塞队列协程在入队时的顺序不对，查看波形，发现在注册中断处理协程时，入队下一个周期就马上入队了，因此顺序不正确
  - 接口对应的 interrupt 线在 verilog 中找不到，并且将阻塞队列的 deq.valid 直接连接到了 enq.ready，因此入队后会马上出队
  - 似乎是因为 chisel 提供的 queue 实现的原因，不管有没有使能，出队的 bits 总会指向队首的数据
  - 不考虑从设备的中断线传输到中断控制器这部分周期，中断控制器里的中断处理为 4 个时钟周期

##### 20240305

- 组会
- 将外部中断连接到中断控制器中
  - 在 LazyModule 类中添加 intnode（IntNexusNode）节点，在外层的 CanHavePeripheryATSINTC trait 中将这个 intnode 连接到 ibus.toPLIC
- 定义了 InterruptHandler 类，其中集成了队列，针对每个中断线，产生一个对应的中断处理模块
  - 提供一个 enq 接口，用于软件注册中断处理例程
  - 提供一个 deq 接口，连接到优先级队列的 enq0 接口，假定都为优先级最高，当外部中断信号被拉高时，将会产生一个信号，从内部集成的队列中取出中断处理例程，然后通过 deq 接口将其加入到优先级队列中
  - 入队正常工作
  - 出队还需要通过连接外设进行测试才可以
- 尝试直接在 rocket-chip 中直接找一个 gpio，将其连接到外部中断信号线上，直接在 verilator 中进行测试，而不用在真板子上测试（太耗时间）
  - 想复杂了，可以直接写 MMIO 寄存器，来模拟产生一个中断信号，验证基本的功能
  - 写完 MMIO 寄存器后，不能从优先级队列中取出中断处理例程，应该是入队的部分还存在问题，从波形中也看不到任何入队的操作

##### 20240304

- 突然想起昨天上板子测试，没有执行 make build 更换项目的 rocketchip-axu15eg.v，检查发现确实没有相关的优先级队列的代码
  - LUT: 33% -> 53%
  - 能够通过测试
- 写学期计划
- 完善设计文档
  - 画行为图
  - 补充接口的描述，在何时使用
- 测试硬件优先级队列出队、入队需要的 cycle，均在 40 个 cycle

##### 20240303

- 在 index block 中增加索引递增递减的功能，但是 position 计算错误，之前的写法有问题
- 基本的功能正常了，但是最后一个优先级的入队还存在问题，因为多了一个 eof 的索引，但是在计算时溢出了，导致计算的位置取到了优先级为 0 的索引
- 硬件优先级队列全部实现，并且连接到 rocket-chip 中，经过 verilator 验证，逻辑正常
- 合并 LX 的 pr
- 在 FPGA 上测试硬件优先级队列，与在 verilator 上的行为不符合，还需要用 ila 抓一下信号线才行
  - LUT 使用率为 33%

##### 20240302

- 写 index block，能够正常工作，将 index block 与 data array 连接在一起，正常工作

##### 20240301

- 硬件队列 debug，chisel 转化成 verilog 时，将 ready 和 valid 直接用组合逻辑连接在一起，导致了 `Combinational loop detected` 错误。
- 在单元测试时，能够正常工作，接入到 rocket-chip 时出现错误，查看波形，发现两边的 ReadyValid 接口部分信号线没有显示，mem 入队不正常，但 mem 出队的功能正常
- debug 硬件队列，出对和入队正常，能够在任意位置入队

##### 20240229

- 写 chisel 硬件代码实现，实现了一个高级的队列，能够在任意位置插入元素，从队头取出元素
- 修改简历
- 将自己实现的队列放到 rocket-chip 中出现错误：`Exception in thread "main" firrtl.transforms.CheckCombLoops$CombLoopException: : [module ExampleRocketSystem] Combinational loop detected`，可能是因为自己的队列中有些信号使用组合逻辑实现的

##### 20240228

- 开会讨论
- 阅读论文 EFFICIENT PRIORITY-QUEUE DATA STRUCTURE FOR HARDWARE IMPLEMENTATION
- 阅读代码 https://github.com/joonho3020/chisel-priorityqueue，代码并不是按照论文中描述的那样实现的，还是 用移位寄存器的方式，将输入信号广播到所有的数据块。
- 根据论文写优先级队列实现

##### 20240227

- 学习 SyetemVerilog，尝试把已有的优先级队列代码转换成 chisel 代码
- 找到了已有的 chisel 优先级队列实现，所以跳过学习 SystemVerilog
  - https://github.com/joonho3020/chisel-priorityqueue，根据 [Efficient Priority-Queue Data Structure for Hardware Implementation](https://ieeexplore.ieee.org/document/4380693) 实现的
  - [Chisel-based Implementation of High-performance Pipelined Priority Queue Generator](https://ieeexplore.ieee.org/document/9730477) 是 2022 年发表的
- 阅读论文 Chisel-based Implementation of High-performance Pipelined Priority Queue Generator
- 讨论设计方案
  - 阻塞队列抽象级别，针对网卡，出队入队、以及其他的原因导致的阻塞，如何使用一个比较抽象的接口来处理
  - 收发双方进行通信，处理流程

##### 20240226

- 组会
- 调试硬件
  - chisel 的 regfield 中的读采用 ReadyValidIO，而写采用 DecoupledIO，但这个不存在影响，DecoupledIO 是 ReadyValidIO 的子类
  - 目前的问题，无论是 queue 还是普通的寄存器，在 for 循环中连续的写，从 printf 和波形的结果来看，bits 只拉起了最后一次的数据
  - 在 for 循环中增加了无关的 printf 语句后，相当于增加了一点时间缓冲，输入的波形正常，每次写的 ReadyValidIO 接口的波形是正常的，输出的波形还不太正常，在 enq 的下一个周期，deq 马上会输出
  - 使用 queue 和寄存器都能够正常工作
- 同步小论文反馈意见
- 写硬件行为描述文档，画图
- 练字