[TOC]

## The Design and Implementation of a Log-Structured File System

#### Abstrac：

- 所有文件的修改顺序的添加在 disk 的后面，加速了文件的写以及恢复（消除了所有的寻道）
- disk 上只有唯一的一种数据结构：log，其中包含了索引信息来高效的从 log 中读取数据
- 性能：在小文件写比 UNIX 高一个数量级，在读以及大规模写与 UNIX 相当甚至更优

#### Introduction：

- 现状：CPU 速度不断增加，硬盘速度却增长的缓慢，硬盘读写速度成为大多数应用的瓶颈
- 为了高效，必须保证在写的时候总有足够大的空间，因此将空闲空间划分为 segment，程序 segment cleaner 周期性的压缩严重碎片化的片段来重新生成大的 segment
- segment cleaner 采取的策略：将旧的、变化慢的数据与新的、极速变化的数据区别对待
- 性能：65 ~ 75% 的带宽写数据，剩下的带宽用于 clean（UNIX：5 ~ 10% 的带宽写，剩下的寻道）



#### Desing for file systems of the 1990's

介绍 **技术**以及**任务量**给设计文件系统带来的影响

##### Technology

- 三个重要组件：处理器、硬盘、内存；处理器的速度加快给计算机其他部件的发展带来了压力；硬盘的改进更多的是容量和开销，而不是性能（传输带宽有改进（磁盘阵列以及并联磁头磁盘）、访问时间基本上没有改进）；现代文件系统在内存中缓存了最近的文件数据，内存增大，可以缓存的文件数据更大，通过吸收读取请求可以减少磁盘的工作量，但是最终必须要在磁盘上写入，因此磁盘的性能主要取决于写的性能；大文件缓存可以充当写入的缓冲区，在将任何缓冲区的数据写入磁盘之前可以收集大量修改后的块，使得写数据块更加高效（只需一次寻道），但是也会造成崩溃时丢失的数据更多

##### Workloads

文件系统设计最难有效处理的工作负载是在办公软件核工程软件环境中，这个环境主要取决于访问小文件（小文件经常会产生随机磁盘I/O，创建和删除这些小文件取决于更新文件系统的元数据）

##### Problems with existing file systems

- 将信息分散到磁盘的各个位置，需要多次寻道
- 写数据采取同步的方式，即使 UNIX FFS 写数据块是异步的，但是对于文件系统的元数据的写仍然是同步的

#### Log-structured file systems

将许多的小规模的同步的随机访问转化为大规模的异步顺序传输

关键点：

- 如何从 log 中取回信息
- 如何管理空闲空间，保证写新数据时总有足够大的空间

##### File location and reading

- 在 log 结构中输出索引结构信息，允许随机访问检索
- 一旦找到 inode，LFS 和 UNIX FFS 读文件需要的磁盘 I/O 请求次数相同
- 不把 inode 放在固定位置，而是存放在 log 中，在 log 中维护一个 inode map 数据结构来获得每个 inode 的位置
- inode map 写到 log 中的块上，在一个固定检查区域中包括了所有 inode map 所在的块

##### Free space management: segments

- LFS 将 disk 划分为固定大小的段，段总是从头写到尾，段需要重写时，会复制出里面的活跃数据（段大小通常为 512KB 或 1MB）

##### Segment cleaning mechanism

- 读取多个片段的数据到内存中，识别出活跃的数据，并将它们写回到较少的段中
- segment clean 程序需要识别出一个段中哪些块是活跃的，还需要知道这个块属于哪个文件以及在文件中的位置
- 通过在每个段中存放段摘要信息来解决上述问题（例如：对于每个文件数据块，段摘要信息中包含了所属的文件编号以及块编号）
- LFS 能够通过段摘要信息区分出活跃信息，一旦识别了某个块，那么就可以通过检查所属文件的 inode 或者 间接块上是否有合适的块指针指向这个块这种方式，判断出这个块是否活跃
- LFS简化了活跃性检查，在每个文件的 inode map 实体中记录了版本号，版本号与 inode 编号形式相结合，构成文件内容的唯一标识符 uid，段摘要信息记录了段内每个块的 uid，当块的 uid 与当前 inode map 中保存的不一致，就会直接舍弃这个块
- 删除了 bitmap 和 free_list，减少这部分数据维护和恢复的开销

##### Segment cleaning policies

四个问题：

- 什么时候运行 segment cleaner 程序？以较低的优先级在后台持续运行；只在晚上运行；只在磁盘空间耗尽时
- 一次清理多少个段？一次清理的段的数量越多，段重新安排的机会越多
- 哪些段需要被清理？明显的结果是碎片化最严重的段，但实际上，这并不是最好的选择
- 当活跃的块被写出时，应该怎么组织？一种方式是增强局部性，方便之后的读操作；另一种方式是根据块最后一次修改的时间排序，将 age 相似的块组织到同一个段中（age sort）