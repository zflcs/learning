[TOC]



### SLM-DB: Single-Level Key-Value Store with Persistent Memory

#### Abstract

提出了一种新的 KV 存储，即单级合并 DB（ SLM-DB ），它利用了 B+ 树索引和日志结构合并树（ LSM 树）方法，充分利用了快速持久内存，实现了高读性能和高写性能，具有低写放大率和接近最佳读放大率。

在 SLM-DB 中，利用持久内存来维护 B+ 树索引，并采用LSM树方法将插入的KV对暂存在PM驻留内存缓冲区中。在磁盘上有一个 KV 对的单级组织，并对 KV 对执行选择性压缩，收集垃圾并保持 KV 对充分分类，以便进行范围查询操作。由于插入的 KV 键值对立即保存在 PM 缓冲区中，我们还可以完全消除预写日志，同时提供强大的数据持久性。

广泛的实验研究表明，在默认设置中，与 LevelDB 相比，SLM-DB 提供的读写吞吐量分别高 1.07-1.96 和 1.56-2.22 倍，范围查询性能与 LevelDB 相当。

#### Introduction

KV 存储已成为有效支持各种数据密集型应用的关键组件。两种典型的 KV 存储类型，一种基于 B 树，另一种基于日志结构合并树（LSM树）。

- 基于 B 树的 KV 存储和数据库支持快速读和范围查询，表现出较差的写入性能，主要是因为大多数写都是随机的，并且动态的保持平衡结构会存在高写入放大。
- 基于 LSM 树的 KV 存储能有效支持写密集型工作负载，在内存中缓冲 KV 并以批处理方式顺序写入磁盘。然而，由于 LSM 树由多个文件级别组成，通常对 KV 键值对进行多次合并排序（即压缩）以实现快速搜索，因此它具有高的读写放大率以及低读取性能的挑战性问题。

预计 PM 将会和硬盘共存，因此对于大规模的 KV 存储，数据仍然还是在硬盘上，PM 可以用来改善这个性能，新设计基于 PM 和磁盘混合系统的 KV 存储不仅是一个大的内存读写缓冲，而且是实现更好性能的关键。

在 SLM-DB 中，KV 对存储在具有单一级别组织的磁盘上，需要为存储在磁盘上的 KV 对提供一定程度的顺序性，以便为范围查询提供合理的性能。

**主要贡献：** 

- 单级 KV 存储
- 设计了三种选择性压缩。三种模式分别基于 1）文件数据的 live-key 比例；2）B+ 树扫描的叶节点数；3）每个范围查询的顺序度
- 进行了评估

#### Background and Motivation

讨论基于 LSM 树的 KV 存储及其问题。

##### LevelDB

LSM 树包括两个模块，DRAM 中驻留的 MemTable 和 不可变 MenTable，持久化存储中的多级 SSTable 文件。

MemTable 和 不可变 MemTable 的内存布局是排序的 **跳转表** 。将 KV 对的删除视作更新，用删除标记。

需要写的时候，先写到 MenTable 中，当 MenTable 填满时，转化成不可变 MenTable，通过后台的线程刷新到硬盘上。（崩溃之后的恢复需要在写 MenTable 时先写入日志来保证）当不可变 MenTable 刷新到硬盘时，日志会被删除。默认情况下，LevelDB 不会将 KV 对提交到日志，因为提交的 fsync（）操作会导致写入性能降低。

在硬盘上的 SSTable 被组织成层次的，层次越深，SSTable 文件数目越多；当某一层满了之后，将这一层的某个 SSTable 文件移出来，将其中的 KV 对与下一层的进行合并，保证同一层内不会冗余（存在冗余时，低级别中的会将其覆盖高级别中的，低级别中的总是最新的）。从内存刷新到 L0 时，不执行这个操作，因此 L0 中的 SSTable 会存在冗余的 key。

LevelDB 还在 MANIFEST 的文件中维护当前 LSM 树组织的 SSTable 元数据。元数据包括每个级别中的 SSTable 文件列表以及每个 SSTable 文件的 key 范围。在压缩过程中，将捕获 SSTable 元数据中的更改，例如删除的 SSTable 文件。压缩完成后，首先将更改记录在 MANIFEST 文件中，然后删除过时的 SSTable 文件。通过这种方式来保证一致性。

##### Limitation of LevelDB

**读操作慢：** 从内存再到硬盘中的最浅层到最深层，层次的查找，先找到对应的 SSTable 文件，再从这个文件中用二分查找找到对应的块。

**读写放大高：** 因为 LSM 的层次结构

##### Persistent Memory

PM 将经由存储器总线而不是块接口连接，PM 设备上的故障单位为 8 字节，比传统的设备要小，因此必须保证即使系统崩溃了，数据结构仍然一致。需要仔细更新数据结构，确保内存写的顺序。

#### Single-level Merge DB（SLM-DB）

![image-20221124144924326](SLM-DB Single-Level Key-Value Store with Persistent Memory.assets\image-20221124144924326.png)

在 PM 中保存 MenTable 和不可变 MenTable，因此不需要 WAL 预先写日志，硬盘上的 SSTabel 组织成单层的，减少了必须要的操作。为了加快 SSTable 文件的单级组织上的读取操作，SLM-DB 构建了一个持久的 B+ 树索引。此外，SLM-DB 需要在 SSTables 中保持足够的 KV 顺序（即，KV 对按排序顺序存储的程度），以便能够提供合理的范围查询性能。尽管没有层次的压缩合并，但是还是需要压缩合并组织成有序的状态，因此采用了选择性压缩合并，并且将这个操作的日志记录在 PM 中。

继承了 MenTable 在内存中的组织结构，并将其移到了 PM 上，保留了 SSTable 的磁盘数据结构和文件格式，以及多个 SSTable 文件压缩（即合并排序）方案。还利用了 LSM 树索引结构，它维护了有效 SSTable 文件和 SSTable 文件元数据的列表，将 LSM 树结构中的任何更改记录到 MANIFEST 文件的机制，以及 LevelDB 的恢复方案。使用持久的B+树完全改变了LevelDB实现的随机读取和范围查询操作。使用了 FAST 和 FAIR B 树。（比其他的持久化 B 树性能好，因为它的所有的键值都是顺序存储的，还通过利用内存级别的并行性和相关存储指令的排序约束，获得最高的写入吞吐量）

##### Persistent MemTable

在 PM 中以持久化跳转表的形式组织，可以使用原子操作来完成插入、更新和删除之类的跳转表操作。为了保证在 MenTable 中的一致性，先持久化一个新 node，再调用 fence 和缓存刷新指令设置 node 的下一个指针。

##### B+ tree Index in PM

当 KV 对从 MemTable 刷新到硬盘时，就会把 key 插入到 B+ 树的叶节点中，节点具有指向 PM 对象的指针，Pm 对象中保存着 KV 对再硬盘上的存储位置信息（包括 SSTable 文件 ID，文件中的 block 偏移以及 block 大小）。

**Building a B+ tree：** 在将不可变 MemTable 刷新进硬盘时，会在 B+ 树种插入索引，这个 flush 操作由两个后台线程进行，一个负责创建文件，另一个负责插入到 B+ 树中。**创建文件线程**创建新的 SSTable 文件，并将 KV 对写到文件中，一旦写完，就会把所有的 KV 对放到一个队列（由插入线程创建）中，**插入线程**一个一个的将其插入到 B+ 树中，之后在 MANIFEST 文件中记录 LSM 树组织的更改。最后删除不可变 MeMTable。

**Sacnning a B+ tree：**提供了一个全局的 KV 迭代器。value() 方法会从 SSTable 文件中读取 KV 对。

##### Selective Compaction（选择性压缩合并）

SLM-DB 支持选择性压缩操作，以收集过时的 KV 对，并提高 SSTables 中 KV 对的顺序性。SLM-DB 维护了一个 SSTable 文件 compaction candidate 列表，当 SSTable 文件的组织发生改变，并且对某个 SSTable 进行了大量的搜索之后，后台的**压缩线程**会被调度。当列表长度大于某个阈值时，也会调度压缩线程。

压缩程序执行时，会从候选列表中选出一个 SSTable 文件的子集。会计算某个 SSTable 文件 s 与列表中其他的每个文件 t 之间的 Key 范围重叠比例。如果两个文件 key 范围不重叠，则设置这个比例为 0。通过计算 s 的总体重叠率，选出最大重叠率的 SSTable 文件 s' 与列表中的其他文件合并，并且限制合并的文件数量，避免干扰前台的用户操作。

压缩程序与上述的操作相同，创建两个线程（一个负责创建文件，另一个负责插入）。当合并多个 SSTable 文件时，需要检查每个文件中的 KV 对是否合法或过时，这个通过搜索 B+ 树中的 key 来保证。合法的 KV 将会和其他的合法 KV 合并排序，如果 key 不存在或者存在多个，则会丢弃掉过时的。

SLM-DB 实现了三种选择压缩模式。

1）基于 SSTable 中的 live-key（有效 key）比例；为了回收垃圾。

2）B+ 树中的叶节点扫描；为了改善存储在 L0 上的 KV 对顺序性。循环扫描叶节点，查找固定数量的 key。在扫描期间，会统计唯一 SSTable 文件的数量，如果超过某个阈值，就会把这些文件加入到合并候选列表中。

3）每次范围查询的顺序度；范围查询时，会将范围划分成几个子范围，每个子范围的 key 的数量是预定义的，将会跟踪访问的唯一文件的数量。范围查询结束后，即可找到具有最大的唯一文件数目的子范围。如果子范围的的唯一文件数目超过了阈值，则会将对应的文件加进合并候选列表。

在 PM 中维护了选择性压缩合并的日志（ compaction log）。在压缩合并结束后，日志将会删除。

#### KV Store Operations in SLM-DB

#### Crash Recovery

在 SLM-DB 中，skiplist 被实现为使得 skiplist 的最低级别的链接列表被保证与对 PM 的8字节的原子写入或更新一致，而无需任何日志记录。因此，在恢复过程中，我们可以简单地重建更高级别的 skiplist。

为了利用 LevelDB 的恢复机制，SLMDB 将更多信息添加到 SSTable 元数据中，例如压缩候选列表、为每个 SSTable 存储的有效 KV 对的数量以及 SSTable 中的 KV 对总数。MANIFEST 文件以与原始 SSTable 元数据相同的方式记录附加信息。

#### Experimental Results

随机读写的吞吐量：SLM-DB 比 LevelDB 高；

顺序读的吞吐量：SLM 比 LevelDB 高；

范围查询吞吐量：1、4KB 大小时，LevelDB 高，16、64KB 大小时，SLM-DB 略高。

#### 相关工作

- HiKV：全部使用 PM，不使用硬盘；PM 中维护全局 Hash 索引，内存中维护 B+ 树；

- pmemkv：在 DRAM 中维护 B+ 树的内部节点，在 PM 中维护 B+ 树的叶节点

- NoveLSM 和 NVMRocks 为 PM 重新设计了基于 LSM 树的 KV 存储。NoveLSM 建议在 DRAM MemTable 和磁盘组件之间设置一个不可变的 PM MemTable，从而降低序列化和反序列化成本。此外，还有一个可变的 PM MemTable，它与 DRAM MemTable 一起使用，以减少压缩导致的暂停。

#### 点评：

- 用 DRAM 来模拟 PM
- 多线程的工作负载方面存在限制
- 

